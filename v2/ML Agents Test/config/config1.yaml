behaviors:
    default:
        trainer_type: ppo
        hyperparameters:
            batch_size: 128
            buffer_size: 1280
            learning_rate_schedule: linear
            learning_rate: 3.0e-4
        network_settings:
            hidden_units: 128
            normalize: false
            num_layers: 3
            vis_encode_type: simple
            memory:
                memory_size: 128
                sequence_length: 128
        max_steps: 5.0e5
        time_horizon: 64
        summary_freq: 10000
        reward_signals:
            extrinsic:
                strength: 1.0
                gamma: 0.99
    MoveToGoal:
        trainer_type: ppo
        hyperparameters:
            batch_size: 128
            buffer_size: 1280
        network_settings:
            hidden_units: 128
            num_layers: 3
        max_steps: 5.0e6
        time_horizon: 128
